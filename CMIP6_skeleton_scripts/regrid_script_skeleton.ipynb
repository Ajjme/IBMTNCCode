{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import datetime as dt\n",
    "import sys\n",
    "from glob import glob\n",
    "from scipy.interpolate import RectSphereBivariateSpline # this is the interpolation method package\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: `regrid_ncfile` is the path to the dataset which contains the latitude and longitude vectors you want to interpolate your data to. Alternatively, you may define your own lat and lon by defining `regrid_lat` and `regrid_lon` as some other numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/home/datasets/aos112_2021/AOS112_Lab_1_Projection_monthly_data/cmip5/pr_Amon_ACCESS1-0_historical_r1i1p1_185001-200512_2.5x2.5regrid.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-838927661925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregrid_ncfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/datasets/aos112_2021/AOS112_Lab_1_Projection_monthly_data/cmip5/pr_Amon_ACCESS1-0_historical_r1i1p1_185001-200512_2.5x2.5regrid.nc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mregrid_lat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregrid_ncfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mregrid_lon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregrid_ncfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/home/datasets/aos112_2021/AOS112_Lab_1_Projection_monthly_data/cmip5/pr_Amon_ACCESS1-0_historical_r1i1p1_185001-200512_2.5x2.5regrid.nc'"
     ]
    }
   ],
   "source": [
    "regrid_ncfile = Dataset('/home/datasets/aos112_2021/AOS112_Lab_1_Projection_monthly_data/cmip5/pr_Amon_ACCESS1-0_historical_r1i1p1_185001-200512_2.5x2.5regrid.nc','r')\n",
    "regrid_lat = regrid_ncfile.variables['lat'][:]\n",
    "regrid_lon = regrid_ncfile.variables['lon'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The interpolating scheme works for radian coordinates of which lat is positive from 0 to pi\n",
    "new_lats,new_lons  = np.meshgrid(np.deg2rad(regrid_lat)+np.pi/2,np.deg2rad(regrid_lon))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `data_directory` should be the file path to the data. The data is organized as follows __/data_directory/model_name/hist/tas_hist_files__ and __/data_directory/model_name/ssp585/tas_ssp_files__ . You should have a target directory with subdirectories which are named __model_name__. Within each model subdirectory, you should have two folders, __hist__ and __ssp585__ which contain all the respective __.nc__ data files. \n",
    "\n",
    "The scripts below will loop through each subdirectory and compile all the __hist__ into a single __.nc__ file and the __ssp585__ files into a single file __.nc__ file which will be saved into the user-specfied `target_directory` file path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/home/twemmen/other_data/'\n",
    "target_directory = '/home/twemmen/other_data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`f` is a list of file path to the model subdirectories. \n",
    "\n",
    "`model_names` should be the name of the model subdirectory, listed to check and so that you can copy and paste into other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CESM2',\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = sorted(glob(data_directory +'*'))\n",
    "model_names = [x[len(data_directory):] for x in f]\n",
    "[print('\\'' + x + '\\',') for x in model_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-specified variables below will be used as nested loops, for pointing to files, pulling out variables, and saving the file. You may have more than one type of variable in a file, just put it in the list `variables`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['siconca','tos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the cell below for combining netcdf files *without* interpolation\n",
    "### files will be created in the `target_directory`  , may take awhile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CESM2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twemmen/anaconda3/envs/aos112/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: WARNING: missing_value not used since it\n",
      "cannot be safely cast to variable data type\n"
     ]
    }
   ],
   "source": [
    "for a,i in enumerate(f):\n",
    "    print(model_names[a])\n",
    "    for b,j in enumerate(variables):\n",
    "        for c,k in enumerate(['hist','ssp585']):\n",
    "            g = sorted(glob(i +'/' + k + '/'+ j + '*'))\n",
    "            lat = Dataset(g[0],'r').variables['lat'][:]\n",
    "            lon = Dataset(g[0],'r').variables['lon'][:]\n",
    "            model_time = []\n",
    "            global_var = np.zeros(((2017-1850)*12,len(lat),len(lon))) \n",
    "            global_var[:] = np.nan\n",
    "            time_count = 0\n",
    "            time_str = ['185001-201412','201501-210001']\n",
    "            for d,l in enumerate(g):\n",
    "                ncfile = Dataset(l,'r')\n",
    "                file_time = ncfile.variables['time'][:]\n",
    "                model_time = np.append(model_time,file_time)\n",
    "                global_var[time_count:time_count+len(file_time),:,:] = ncfile.variables[j][:]\n",
    "                time_count = time_count+len(file_time)\n",
    "            \n",
    "            \n",
    "            joint_netcdf = Dataset(target_directory + '/'+ j + '_Amon_' + model_names[a] + '_'+ k + '_'+ time_str[c]+ '_'+str(np.round(np.diff(lat)[0],2)) +'x'+ str(np.round(np.diff(lon)[0],2))+ '.nc','w',format='NETCDF4')\n",
    "\n",
    "            joint_netcdf.createDimension('time',size = len(model_time))\n",
    "            joint_netcdf.createDimension('lat',size = len(lat))\n",
    "            joint_netcdf.createDimension('lon',size = len(lon))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            time_val = joint_netcdf.createVariable('time',np.float64,('time',))\n",
    "            time_val[:] = model_time\n",
    "            time_val.units = ncfile.variables['time'].units\n",
    "            time_val.calendar = ncfile.variables['time'].calendar\n",
    "\n",
    "            lon_val= joint_netcdf.createVariable('lon',np.float64,('lon',))\n",
    "            lon_val.units=\"degree\"\n",
    "            lon_val[:]=lon\n",
    "\n",
    "            lat_val= joint_netcdf.createVariable('lat',np.float64,('lat',))\n",
    "            lat_val.units=\"degree\"\n",
    "            lat_val[:]=lat\n",
    "\n",
    "            var_val = joint_netcdf.createVariable(j,np.float64,('time','lat','lon'))\n",
    "            var_val[:] = global_var[0:len(model_time),:,:]\n",
    "\n",
    "\n",
    "            joint_netcdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tosga': <class 'netCDF4._netCDF4.Variable'>\n",
       " float32 tosga(time)\n",
       "     _FillValue: 1e+20\n",
       "     cell_methods: area: mean where sea time: mean\n",
       "     comment: POP_surf_mean(KMT,TAREA,TEMP[:,0,:,:])\n",
       "     coordinates: time\n",
       "     description: This may differ from \"surface temperature\" in regions of sea ice or floating ice shelves. For models using conservative temperature as the prognostic field, they should report the top ocean layer as surface potential temperature, which is the same as surface in situ temperature.\n",
       "     frequency: mon\n",
       "     id: tosga\n",
       "     long_name: Global Average Sea Surface Temperature\n",
       "     mipTable: Omon\n",
       "     missing_value: 1e+20\n",
       "     out_name: tosga\n",
       "     prov: Omon ((isd.003))\n",
       "     realm: ocean\n",
       "     standard_name: sea_surface_temperature\n",
       "     time: time\n",
       "     time_label: time-mean\n",
       "     time_title: Temporal mean\n",
       "     title: Global Average Sea Surface Temperature\n",
       "     type: real\n",
       "     units: degC\n",
       "     variable_id: tosga\n",
       " unlimited dimensions: time\n",
       " current shape = (600,)\n",
       " filling on,\n",
       " 'time': <class 'netCDF4._netCDF4.Variable'>\n",
       " float64 time(time)\n",
       "     axis: T\n",
       "     bounds: time_bnds\n",
       "     standard_name: time\n",
       "     title: time\n",
       "     type: double\n",
       "     units: days since 0001-01-01 00:00:00\n",
       "     calendar: 365_day\n",
       " unlimited dimensions: time\n",
       " current shape = (600,)\n",
       " filling on, default _FillValue of 9.969209968386869e+36 used,\n",
       " 'time_bnds': <class 'netCDF4._netCDF4.Variable'>\n",
       " float64 time_bnds(time, d2)\n",
       "     calendar: noleap\n",
       "     units: days since 0001-01-01 00:00:00\n",
       " unlimited dimensions: time\n",
       " current shape = (600, 2)\n",
       " filling on, default _FillValue of 9.969209968386869e+36 used}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset(g[0],'r').variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the cell below for combining netcdf files *with* interpolation\n",
    "### files will be created in the `target_directory` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CESM2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twemmen/anaconda3/envs/aos112/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: WARNING: missing_value not used since it\n",
      "cannot be safely cast to variable data type\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPSL-CM6A-LR\n",
      "GISS-E2-1-G\n",
      "MPI-ESM1-2-LR\n",
      "GFDL-ESM4\n",
      "FGOALS-G3\n"
     ]
    }
   ],
   "source": [
    "for a,i in enumerate(f):\n",
    "    print(model_names[a])\n",
    "    for b,j in enumerate(['pr','tas']):\n",
    "        for c,k in enumerate(['hist','ssp585']):\n",
    "            g = sorted(glob(i +'/' + k + '/'+ j + '*'))\n",
    "            model_lat = Dataset(g[0],'r').variables['lat'][:]\n",
    "            model_lon = Dataset(g[0],'r').variables['lon'][:]                \n",
    "            lats      = np.deg2rad(model_lat)+np.pi/2\n",
    "            lons      = np.deg2rad(model_lon)  \n",
    "            model_time = []\n",
    "            global_var = np.zeros(((2017-1850)*12,len(regrid_lat),len(regrid_lon)))\n",
    "            global_var[:] = np.nan\n",
    "            time_count = 0\n",
    "            time_str = ['185001-201412','201501-210001']\n",
    "            for d,l in enumerate(g):\n",
    "                ncfile = Dataset(l,'r')\n",
    "                file_time = ncfile.variables['time'][:]\n",
    "                model_time = np.append(model_time,file_time)\n",
    "                temp_data = ncfile.variables[j][:]\n",
    "                \n",
    "                for m in np.arange(len(file_time)):\n",
    "\n",
    "                    if np.sum(np.logical_or(model_lat>=90,model_lat<=-90))>0:\n",
    "                        valid_lats = np.squeeze(np.where(np.logical_and(model_lat<90,model_lat>-90)))\n",
    "                        interp_cmip6    = RectSphereBivariateSpline(lats[valid_lats], lons, temp_data[m,valid_lats,:]) \n",
    "                        regrid_cmip6    = interp_cmip6.ev(new_lats.ravel(),new_lons.ravel()).reshape((len(regrid_lon),len(regrid_lat))).T\n",
    "\n",
    "                    else:       \n",
    "                        interp_cmip6    = RectSphereBivariateSpline(lats, lons, temp_data[m]) \n",
    "                        regrid_cmip6    = interp_cmip6.ev(new_lats.ravel(),new_lons.ravel()).reshape((len(regrid_lon),len(regrid_lat))).T\n",
    "\n",
    "                    global_var[time_count+m,:,:] = regrid_cmip6\n",
    "                \n",
    "                time_count = time_count+len(file_time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            joint_netcdf = Dataset(target_directory + '/'+ j + '_Amon_' + model_names[a] + '_'+ k + '_'+ time_str[c]+ '_regrid.nc','w',format='NETCDF4')\n",
    "\n",
    "            joint_netcdf.createDimension('time',size = len(model_time))\n",
    "            joint_netcdf.createDimension('lat',size = len(regrid_lat))\n",
    "            joint_netcdf.createDimension('lon',size = len(regrid_lon))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            time_val = joint_netcdf.createVariable('time',np.float64,('time',))\n",
    "            time_val[:] = model_time\n",
    "            time_val.units = ncfile.variables['time'].units\n",
    "            time_val.calendar = ncfile.variables['time'].calendar\n",
    "\n",
    "            lon_val= joint_netcdf.createVariable('lon',np.float64,('lon',))\n",
    "            lon_val.units=\"degree\"\n",
    "            lon_val[:]=regrid_lon\n",
    "\n",
    "            lat_val= joint_netcdf.createVariable('lat',np.float64,('lat',))\n",
    "            lat_val.units=\"degree\"\n",
    "            lat_val[:]=regrid_lat\n",
    "\n",
    "            var_val = joint_netcdf.createVariable(j,np.float64,('time','lat','lon'))\n",
    "            var_val[:] = global_var[0:len(model_time),:,:]\n",
    "\n",
    "\n",
    "            joint_netcdf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aos112",
   "language": "python",
   "name": "aos112"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
